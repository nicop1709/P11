# Solution avec findspark pour EMR
# findspark g√®re automatiquement la configuration Java et Spark

print("üîß Configuration avec findspark...")
print("=" * 70)

# 1. Installer findspark
print("\n1Ô∏è‚É£  Installation de findspark...")
import subprocess
import sys

try:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'findspark', '--user', '--quiet'])
    print("‚úÖ findspark install√©")
except Exception as e:
    print(f"‚ö†Ô∏è  Erreur lors de l'installation: {e}")
    print("   (findspark peut d√©j√† √™tre install√©)")

# 2. Utiliser findspark
print("\n2Ô∏è‚É£  Initialisation de findspark...")
import findspark

# Chercher Spark automatiquement
# findspark va chercher dans les chemins courants d'EMR
try:
    # Essayer d'abord sans param√®tre (recherche automatique)
    findspark.init()
    print("‚úÖ findspark initialis√© (recherche automatique)")
except Exception as e:
    print(f"‚ö†Ô∏è  Recherche automatique √©chou√©e: {e}")
    print("   Tentative avec chemin explicite...")
    
    # Essayer avec le chemin EMR standard
    spark_paths = [
        '/usr/lib/spark',
        '/opt/spark',
    ]
    
    for spark_path in spark_paths:
        try:
            findspark.init(spark_path)
            print(f"‚úÖ findspark initialis√© avec: {spark_path}")
            break
        except:
            continue
    else:
        print("‚ùå Impossible d'initialiser findspark")
        raise Exception("findspark.init() a √©chou√©")

# 3. V√©rifier la configuration
print("\n3Ô∏è‚É£  V√©rification de la configuration...")
import os
print(f"JAVA_HOME: {os.environ.get('JAVA_HOME', 'Non d√©fini')}")
print(f"SPARK_HOME: {os.environ.get('SPARK_HOME', 'Non d√©fini')}")

# 4. Cr√©er SparkSession
print("\n4Ô∏è‚É£  Cr√©ation de SparkSession...")
print("-" * 70)

from pyspark.sql import SparkSession

try:
    spark = (SparkSession
             .builder
             .appName('P8')
             .config("spark.sql.parquet.writeLegacyFormat", 'true')
             .getOrCreate()
    )
    
    print("‚úÖ SparkSession cr√©√©e avec succ√®s!")
    print(f"   Spark version: {spark.version}")
    print(f"   Spark master: {spark.sparkContext.master}")
    print(f"   App name: {spark.sparkContext.appName}")
    
except Exception as e:
    print(f"‚ùå Erreur lors de la cr√©ation de SparkSession:")
    print(f"   {type(e).__name__}: {e}")
    print("\nüí° Solutions possibles:")
    print("   1. Red√©marrer le serveur JupyterHub")
    print("   2. V√©rifier que le cluster EMR est actif")
    print("   3. Utiliser le kernel PySpark (si disponible)")
    raise

print("\n" + "=" * 70)
print("‚úÖ Configuration termin√©e! Spark est pr√™t √† √™tre utilis√©.")
print("üí° Testez avec: spark.range(10).show()")
