# Configuration Spark pour EMR - Chemins exacts
# √Ä ex√©cuter dans la premi√®re cellule d'un notebook Python

import os
import sys
import glob

print("üîß Configuration de l'environnement Spark pour EMR...")
print("=" * 60)

# 1. Configurer JAVA_HOME (chemin exact trouv√© sur le cluster)
java_home = '/etc/alternatives/jre'
if os.path.exists(java_home):
    os.environ['JAVA_HOME'] = java_home
    print(f"‚úÖ JAVA_HOME: {java_home}")
else:
    # Fallback vers les chemins courants
    java_paths = [
        '/usr/lib/jvm/java-8-openjdk-amd64',
        '/usr/lib/jvm/java-8-openjdk',
        '/usr/lib/jvm/java-1.8.0-openjdk-amd64',
    ]
    for path in java_paths:
        if os.path.exists(path):
            os.environ['JAVA_HOME'] = path
            print(f"‚úÖ JAVA_HOME (fallback): {path}")
            break

# 2. Configurer SPARK_HOME
spark_home = '/usr/lib/spark'
if os.path.exists(spark_home):
    os.environ['SPARK_HOME'] = spark_home
    print(f"‚úÖ SPARK_HOME: {spark_home}")
    
    # Ajouter Spark Python au PYTHONPATH
    spark_python = f'{spark_home}/python'
    if os.path.exists(spark_python):
        if spark_python not in sys.path:
            sys.path.insert(0, spark_python)
        print(f"‚úÖ Spark Python ajout√© au PYTHONPATH")
    
    # Ajouter py4j (chemin exact: py4j-0.10.9.7-src.zip)
    py4j_path = f'{spark_home}/python/lib/py4j-0.10.9.7-src.zip'
    if os.path.exists(py4j_path):
        if py4j_path not in sys.path:
            sys.path.insert(0, py4j_path)
        print(f"‚úÖ py4j ajout√©: py4j-0.10.9.7-src.zip")
    else:
        # Fallback: chercher n'importe quel py4j
        py4j_pattern = f'{spark_home}/python/lib/py4j-*.zip'
        py4j_matches = glob.glob(py4j_pattern)
        if py4j_matches:
            for match in py4j_matches:
                if match not in sys.path:
                    sys.path.insert(0, match)
            print(f"‚úÖ py4j ajout√© (fallback): {py4j_matches[0]}")
        else:
            print("‚ö†Ô∏è  py4j non trouv√©")
    
    # Ajouter pyspark.zip
    pyspark_zip = f'{spark_home}/python/lib/pyspark.zip'
    if os.path.exists(pyspark_zip):
        if pyspark_zip not in sys.path:
            sys.path.insert(0, pyspark_zip)
        print(f"‚úÖ pyspark.zip ajout√©")
else:
    print("‚ùå SPARK_HOME non trouv√©")

# 3. V√©rifications finales
print("\nüìã Configuration finale:")
print("-" * 60)
print(f"JAVA_HOME: {os.environ.get('JAVA_HOME', 'Non d√©fini')}")
print(f"SPARK_HOME: {os.environ.get('SPARK_HOME', 'Non d√©fini')}")

# 4. Cr√©er SparkSession
print("\nüöÄ Cr√©ation de la SparkSession...")
print("-" * 60)

try:
    from pyspark.sql import SparkSession
    
    spark = (SparkSession
             .builder
             .appName('P8')
             .config("spark.sql.parquet.writeLegacyFormat", 'true')
             .getOrCreate()
    )
    
    print("‚úÖ SparkSession cr√©√©e avec succ√®s!")
    print(f"   Spark version: {spark.version}")
    print(f"   Spark master: {spark.sparkContext.master}")
    print(f"   App name: {spark.sparkContext.appName}")
    
except Exception as e:
    print(f"‚ùå Erreur lors de la cr√©ation de SparkSession:")
    print(f"   {type(e).__name__}: {e}")
    print("\nüí° Solutions possibles:")
    print("   1. Red√©marrer le serveur JupyterHub")
    print("   2. V√©rifier que le cluster EMR est actif")
    print("   3. V√©rifier les logs du serveur")
    raise

print("\n" + "=" * 60)
print("‚úÖ Configuration termin√©e! Vous pouvez maintenant utiliser Spark.")
print("üí° Testez avec: spark.range(10).show()")
