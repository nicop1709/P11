# ğŸ Classification d'Images de Fruits avec AWS EMR

Projet de traitement Big Data pour la classification d'images de fruits utilisant Apache Spark, TensorFlow et AWS EMR.

## ğŸ“‹ Ã€ propos du projet

Ce projet a Ã©tÃ© dÃ©veloppÃ© pour **Fruits!**, une start-up AgriTech qui souhaite proposer des solutions innovantes pour la rÃ©colte des fruits. L'objectif Ã©tait de crÃ©er une chaÃ®ne de traitement Big Data capable de :

- Traiter de grandes quantitÃ©s d'images de fruits en mode distribuÃ©
- Extraire des features Ã  l'aide d'un modÃ¨le de deep learning (MobileNetV2)
- RÃ©duire la dimensionnalitÃ© des donnÃ©es pour optimiser le stockage et les performances
- Anticiper une montÃ©e en charge future grÃ¢ce Ã  une architecture scalable sur le cloud

Le projet dÃ©montre la mise en place d'une infrastructure Big Data complÃ¨te, de la configuration de l'environnement AWS jusqu'au traitement distribuÃ© de plus de 42 000 images.

## ğŸ—ï¸ Architecture technique

### Stack technologique

- **Calcul distribuÃ©** : Apache Spark 4.0.1 avec PySpark
- **Deep Learning** : TensorFlow 2.20.0 avec MobileNetV2 (transfer learning)
- **Cloud** : AWS EMR (Elastic MapReduce)
- **Stockage** : Amazon S3 (bucket `p11-nicop-data`)
- **RÃ©duction de dimensionnalitÃ©** : PCA avec 50 composantes principales
- **Format de donnÃ©es** : Parquet (compression Snappy)

### Infrastructure AWS

Le projet utilise un cluster EMR configurÃ© avec :

- **1 nÅ“ud maÃ®tre + 2 nÅ“uds workers** (type `m5.xlarge`)
- **RÃ©gion** : `eu-west-3` (Paris)
- **Applications** : Spark, Hadoop, JupyterHub, TensorFlow
- **Connexion sÃ©curisÃ©e** : Tunnel SSH SOCKS5 (port 8157) avec proxy systÃ¨me Mac

L'accÃ¨s Ã  JupyterHub se fait via un tunnel SSH sÃ©curisÃ©, permettant de travailler sur le cluster depuis une machine locale tout en bÃ©nÃ©ficiant de la puissance de calcul distribuÃ©e.

## ğŸš€ FonctionnalitÃ©s principales

### 1. Configuration et gestion de l'infrastructure

Le projet inclut une suite complÃ¨te de scripts pour gÃ©rer l'infrastructure AWS :

**Scripts de configuration** :
- CrÃ©ation interactive de clusters EMR
- Configuration automatique des tunnels SSH
- Gestion du proxy systÃ¨me pour l'accÃ¨s Ã  JupyterHub
- CrÃ©ation et gestion des rÃ´les IAM
- Gestion des clÃ©s EC2 par rÃ©gion

**Scripts de vÃ©rification** :
- Diagnostic complet de l'Ã©tat du systÃ¨me (cluster, tunnel, proxy)
- VÃ©rification de l'Ã©tat des clusters EMR
- Tests de connectivitÃ© rÃ©seau

### 2. Pipeline de traitement des donnÃ©es

Le pipeline implÃ©mentÃ© traite les images en plusieurs Ã©tapes :

1. **Chargement distribuÃ©** : 42 749 images JPG chargÃ©es depuis S3 en utilisant le format `binaryFile` de Spark
2. **Extraction de features** : Utilisation de MobileNetV2 prÃ©-entraÃ®nÃ© sur ImageNet pour extraire 1280 features par image
3. **Preprocessing** : Redimensionnement Ã  224x224 pixels et normalisation
4. **RÃ©duction de dimensionnalitÃ©** : Application d'une PCA pour rÃ©duire Ã  50 dimensions (83% de variance expliquÃ©e)
5. **Sauvegarde** : Stockage au format Parquet sur S3 avec partitionnement optimisÃ©

### 3. Optimisations techniques

Plusieurs optimisations ont Ã©tÃ© mises en place pour amÃ©liorer les performances :

- **RÃ©partition intelligente** : Les donnÃ©es sont rÃ©parties sur 24 partitions pour maximiser le parallÃ©lisme
- **Broadcast des modÃ¨les** : Les poids du modÃ¨le MobileNetV2 sont broadcastÃ©s aux workers pour Ã©viter les tÃ©lÃ©chargements rÃ©pÃ©tÃ©s
- **Pandas UDF** : Utilisation de Scalar Iterator UDF pour optimiser le transfert de donnÃ©es entre Spark et Python
- **Format Parquet** : Stockage efficace avec compression Snappy

## ğŸ“Š RÃ©sultats

### DonnÃ©es traitÃ©es

- âœ… **42 749 images** traitÃ©es avec succÃ¨s
- âœ… **1280 features** extraites par image (MobileNetV2)
- âœ… **50 dimensions** aprÃ¨s rÃ©duction PCA
- âœ… **83% de variance** expliquÃ©e par la PCA

### Datasets gÃ©nÃ©rÃ©s

Les rÃ©sultats sont stockÃ©s sur S3 dans deux datasets :

- **`Results/`** : Features complÃ¨tes (1280 dimensions) - 24 partitions Parquet
- **`Results_PCA/`** : Features rÃ©duites (50 dimensions) - 2 partitions Parquet

Les donnÃ©es ont Ã©tÃ© validÃ©es en les relisant avec pandas, confirmant l'intÃ©gritÃ© et la cohÃ©rence des rÃ©sultats.

## ğŸ“ Structure du projet

```
P11/
â”œâ”€â”€ docs/                    # Documentation complÃ¨te du projet
â”‚   â”œâ”€â”€ guides-principaux/   # Guides essentiels
â”‚   â”œâ”€â”€ guides-depannage/    # Solutions aux problÃ¨mes courants
â”‚   â”œâ”€â”€ guides-configuration/# Configuration AWS
â”‚   â””â”€â”€ guides-pratiques/    # Informations pratiques
â”œâ”€â”€ scripts/                 # Scripts d'automatisation
â”‚   â”œâ”€â”€ setup/              # Configuration initiale
â”‚   â”œâ”€â”€ verification/       # VÃ©rification et diagnostic
â”‚   â”œâ”€â”€ network/           # Gestion rÃ©seau/tunnel
â”‚   â”œâ”€â”€ utils/             # Utilitaires
â”‚   â”œâ”€â”€ solutions/         # Scripts Python de solutions
â”‚   â””â”€â”€ config/            # Configuration Spark
â”œâ”€â”€ data/                   # DonnÃ©es locales (si prÃ©sentes)
â”œâ”€â”€ img/                    # Images de documentation
â”œâ”€â”€ P11_Notebook_EMR.ipynb  # Notebook principal (exÃ©cutÃ©)
â””â”€â”€ P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb  # Notebook de rÃ©fÃ©rence
```

## ğŸ› ï¸ DÃ©marrage rapide

### PrÃ©requis

- AWS CLI configurÃ© avec les credentials appropriÃ©s
- AccÃ¨s Ã  un compte AWS avec permissions EMR
- Machine locale (Mac recommandÃ© pour les scripts de proxy)
- ClÃ© SSH EC2 crÃ©Ã©e dans la rÃ©gion cible

### Ã‰tapes principales

1. **CrÃ©er un cluster EMR** :
   ```bash
   ./scripts/setup/creer_cluster_emr.sh
   ```

2. **Configurer le tunnel SSH** :
   ```bash
   ./scripts/setup/creer_tunnel_ssh.sh
   ```

3. **Activer le proxy systÃ¨me** :
   ```bash
   ./scripts/network/gerer_proxy_mac.sh
   ```

4. **AccÃ©der Ã  JupyterHub** :
   - Ouvrir `https://<master-dns>:9443` dans votre navigateur
   - Le proxy systÃ¨me redirige automatiquement le trafic

5. **ExÃ©cuter le notebook** :
   - Ouvrir `P11_Notebook_EMR.ipynb` dans JupyterHub
   - Suivre les cellules dans l'ordre

Pour plus de dÃ©tails, consultez la [documentation complÃ¨te](docs/README.md).

## ğŸ“š Documentation

Le projet inclut une documentation complÃ¨te organisÃ©e par catÃ©gories :

- **[Guides principaux](docs/guides-principaux/)** : Documentation essentielle pour comprendre et utiliser le projet
- **[Guides de dÃ©pannage](docs/guides-depannage/)** : Solutions aux problÃ¨mes courants
- **[Guides de configuration](docs/guides-configuration/)** : Configuration dÃ©taillÃ©e de l'infrastructure AWS
- **[Guides pratiques](docs/guides-pratiques/)** : Informations sur les coÃ»ts, gestion du compte AWS, etc.

## ğŸ”’ SÃ©curitÃ©

Tous les scripts ont Ã©tÃ© vÃ©rifiÃ©s pour Ã©viter l'exposition d'informations sensibles :

- âœ… Aucune clÃ© API hardcodÃ©e
- âœ… Aucun mot de passe en clair
- âœ… Les identifiants de cluster sont demandÃ©s Ã  l'utilisateur ou via variables d'environnement
- âœ… Les chemins de clÃ©s SSH utilisent des variables avec expansion

Consultez le [rapport de confidentialitÃ©](scripts/RAPPORT_CONFIDENTIALITE.md) pour plus de dÃ©tails.

## ğŸ’° CoÃ»ts

âš ï¸ **Important** : AWS EMR n'est pas gratuit, mÃªme avec le Free Tier.

- CoÃ»t estimÃ© : ~0.50-0.60 â‚¬/heure pour un cluster m5.xlarge (1 maÃ®tre + 2 workers)
- **N'oubliez pas de rÃ©silier le cluster** aprÃ¨s utilisation pour Ã©viter les coÃ»ts inutiles

Pour plus d'informations sur les coÃ»ts, voir [COUTS_EMR.md](docs/guides-pratiques/COUTS_EMR.md).

## ğŸ¯ Prochaines Ã©tapes

Ce projet dÃ©montre la capacitÃ© Ã  :

- âœ… DÃ©ployer une infrastructure Big Data sur AWS
- âœ… Traiter de grandes quantitÃ©s d'images avec Spark et TensorFlow
- âœ… Optimiser les performances avec le calcul distribuÃ©
- âœ… GÃ©rer l'infrastructure cloud de maniÃ¨re sÃ©curisÃ©e

Les donnÃ©es traitÃ©es peuvent maintenant Ãªtre utilisÃ©es pour :
- EntraÃ®ner des modÃ¨les de classification
- CrÃ©er des applications de reconnaissance de fruits
- Analyser la biodiversitÃ© des fruits

## ğŸ“ Notes techniques

### RÃ©solution de problÃ¨mes

Plusieurs dÃ©fis techniques ont Ã©tÃ© rÃ©solus au cours du projet :

- **Configuration Spark sur EMR** : Installation de Java 17 et configuration des variables d'environnement
- **IntÃ©gration S3** : Configuration de Hadoop AWS (S3A) pour l'accÃ¨s aux donnÃ©es
- **Connexion JupyterHub** : Mise en place d'un tunnel SSH SOCKS5 avec proxy systÃ¨me
- **Optimisation TensorFlow + Spark** : Utilisation de Pandas UDF et broadcast des modÃ¨les

Toutes les solutions sont documentÃ©es dans les guides de dÃ©pannage.

## ğŸ‘¤ Auteur

Projet rÃ©alisÃ© dans le cadre de la formation OpenClassRooms IngÃ©nieur IA.

## ğŸ“„ Licence

Ce projet est fourni Ã  titre Ã©ducatif et de dÃ©monstration.

---

*DerniÃ¨re mise Ã  jour : Janvier 2026*
